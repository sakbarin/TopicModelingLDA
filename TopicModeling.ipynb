{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions, types\n",
    "from bs4 import BeautifulSoup\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import LDA\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Businesses Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read business json file\n",
    "df_init_business = spark.read.json('business.json')\n",
    "\n",
    "# filter only restaurants in Toronto\n",
    "df_filter_business = df_init_business.where((functions.lower(df_init_business['categories']).contains('restaurant')) & (functions.lower(df_init_business['city']) == 'toronto'))\n",
    "\n",
    "# select required columns\n",
    "df_business = df_filter_business.select(df_filter_business['business_id'], df_filter_business['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Reviews Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read reviews json file\n",
    "df_init_review = spark.read.json('review.json')\n",
    "\n",
    "# get only reviews for filtered businesses\n",
    "df_business_reviews = df_business.join(df_init_review, 'business_id', 'left')\n",
    "\n",
    "# filter reviews\n",
    "df_filter_reviews = df_business_reviews.where(df_business_reviews['text'] != '')\n",
    "\n",
    "# select required columns\n",
    "df_reviews = df_business_reviews.select(df_business_reviews['review_id'], df_business_reviews['business_id'], functions.lower(df_business_reviews['text']).alias('review_text')) \\\n",
    "                .cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One sample of review text before processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"so i've never been to the shop, but i see this lady at the montgomery inn farmers market.  sometimes i get a scone or a butter tart and they are always delicious (earl grey and white chocolate scone... mmmm so good).\\nso i have been having a craving for a slice of cherry pie since my birthday (beginning of feb).  i'm not gonna lie, i was imagining the overly sweet sugar coated crust with canned filling... not sure why?  so, last week i'm going in for my scone when what do i see.... a mini cherry pie!  at $7 i'm thinking what a steal to fulfill my birthday dream!  i have enjoyed this amazing little pie on two different occasions with one little piece still remaining.  i'm overjoyed every time i take a bite.  and it's not that super sweet processed cherries from a can pie i'd envisioned.  it's the real thing!  perfect amount of sweet, real cherries and a great crust.  happy birthday to me.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_reviews.take(1)[0][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to remove HTML tags from reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functions.udf(returnType=types.StringType())\n",
    "def remove_html(input):\n",
    "    soup = BeautifulSoup(input, 'html.parser')\n",
    "    return soup.get_text().strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to remove punctuation from review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functions.udf(returnType=types.StringType())\n",
    "def remove_punctuation(input):\n",
    "    output = re.sub(r'[^a-zA-Z0-9]|[0-9]', r' ', input).strip().lower()\n",
    "    output = \" \".join(output.split())\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove HTML tags and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews_nohtml = df_reviews.select(df_reviews['review_id'], df_reviews['business_id'], remove_html(df_reviews['review_text']).alias('review_text'))\n",
    "df_reviews_nopunc = df_reviews_nohtml.select(df_reviews_nohtml['review_id'], df_reviews_nohtml['business_id'], remove_punctuation(df_reviews_nohtml['review_text']).alias('review_text'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of review text after processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'so i ve never been to the shop but i see this lady at the montgomery inn farmers market sometimes i get a scone or a butter tart and they are always delicious earl grey and white chocolate scone mmmm so good so i have been having a craving for a slice of cherry pie since my birthday beginning of feb i m not gonna lie i was imagining the overly sweet sugar coated crust with canned filling not sure why so last week i m going in for my scone when what do i see a mini cherry pie at i m thinking what a steal to fulfill my birthday dream i have enjoyed this amazing little pie on two different occasions with one little piece still remaining i m overjoyed every time i take a bite and it s not that super sweet processed cherries from a can pie i d envisioned it s the real thing perfect amount of sweet real cherries and a great crust happy birthday to me'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_review_nopunc.take(1)[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|           review_id|         business_id|         review_text|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|vrrSIexTsWMrHOCLC...|1RFIVcZYV77tGIwVV...|so i ve never bee...|\n",
      "|mvD1fHMQqzS_f4sqz...|1RFIVcZYV77tGIwVV...|louise is the own...|\n",
      "|3oD2wWuhO-TUjqWnN...|1RFIVcZYV77tGIwVV...|the owner is very...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_review_nopunc.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define additional stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "moreStopWords = \\\n",
    "    ['', 'm', 's', 've', 're', 'com', 'de', 'eu', 'cf', 'pm', 'like', 'one', 'using', 'new', 'also',\n",
    "     'really', 'need', 'caption', 'since', 'change', 'young', 'align', 'width',\n",
    "     'attachment', 'number', 'know', 'two', 'use', 'see', 'get', 'first', 'good',\n",
    "     'next', 'well', 'day', 'way', 'fruit', 'different', 'let', 'lot', 'would',\n",
    "     'already', 'set', 'user', 'even', 'might', 'many', 'different', 'crazy',\n",
    "     'may', 'could', 'still', 'probably', 'make', 'write', 'used', 'written',\n",
    "     'go', 'us', 'yes', 'seen', 'behind', 'much', 'makes', 'via', 'based',\n",
    "     'choose', 'presented', 'away', 'hence', 'wants', 'please', 'add',\n",
    "     'something', 'conclusion', 'able', 'describe', 'thing', 'likely',\n",
    "     'lots', 'sense', 'higher', 'every', 'right', 'sure', 'quite', 'without',\n",
    "     'within', 'codecentric', 'follow', 'look', 'example', 'examples', 'short',\n",
    "     'cancel', 'promise', 'means', 'almost', 'large', 'besides']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove white spaces, stop words and create count vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "regexTokenizer = RegexTokenizer(inputCol=\"review_text\", outputCol=\"review_words\", gaps=True, pattern=r'\\s+', minTokenLength=2)\n",
    "stopWordsRemover = StopWordsRemover(inputCol=\"review_words\", outputCol=\"review_filtered\")\n",
    "countVectorizer = CountVectorizer(inputCol=\"review_filtered\", outputCol=\"features\", vocabSize=2500, minTF=2, minDF=4)\n",
    "\n",
    "stopWordsRemover.setStopWords(stopWordsRemover.getStopWords() + moreStopWords)\n",
    "\n",
    "pipeline = Pipeline(stages=[regexTokenizer, stopWordsRemover, countVectorizer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to see vocabulary\n",
    "#model.stages[2].vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------------------------------------------------------------------------------+\n",
      "|review_id             |features                                                                                 |\n",
      "+----------------------+-----------------------------------------------------------------------------------------+\n",
      "|vrrSIexTsWMrHOCLCPw32g|(2500,[19,85,336,413,562,615,1763],[2.0,3.0,2.0,3.0,2.0,4.0,2.0])                        |\n",
      "|mvD1fHMQqzS_f4sqzDu1oQ|(2500,[17,30,92,177,249,413,516,792,1668,1763],[2.0,2.0,2.0,2.0,3.0,3.0,2.0,2.0,2.0,2.0])|\n",
      "|3oD2wWuhO-TUjqWnNStkDw|(2500,[111],[2.0])                                                                       |\n",
      "|NwrSFI0pJQfiNdJb8IS49A|(2500,[85],[2.0])                                                                        |\n",
      "|7aA5gWum--OxUmk4z8kd1A|(2500,[7],[2.0])                                                                         |\n",
      "|0Z3yFyTE8ZB-lAKyLmVnZg|(2500,[794],[3.0])                                                                       |\n",
      "|VGY2pt1f0gJRV7M_E9PeZQ|(2500,[1,34,226,794],[2.0,2.0,2.0,2.0])                                                  |\n",
      "|SnSzV4_NOxDdrL-QzfEwRQ|(2500,[],[])                                                                             |\n",
      "|0-SLysteTHTn2SGEt9sQHQ|(2500,[43,92,561,794,1901],[2.0,2.0,4.0,4.0,2.0])                                        |\n",
      "|4n9y5mDjvB5sZQnaOdynZQ|(2500,[],[])                                                                             |\n",
      "+----------------------+-----------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = pipeline.fit(df_reviews_nopunc)\n",
    "\n",
    "df_countVectors = model.transform(df_reviews_nopunc).select(\"review_id\", \"features\")\n",
    "df_countVectors.show(10, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test LDA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of training set: 282628\n",
      "count of test set: 93978\n"
     ]
    }
   ],
   "source": [
    "# break dataset into train and test set\n",
    "df_train, df_test = df_countVectors.randomSplit([0.75, 0.25])\n",
    "\n",
    "print(\"count of training set: %d\" % (df_train.count()))\n",
    "print(\"count of test set: %d\" % (df_test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of topics to generate\n",
    "number_of_topics = 6\n",
    "\n",
    "# define LDA algorithm parameters\n",
    "lda = LDA(k = number_of_topics, seed = 1, optimizer=\"online\", \n",
    "          optimizeDocConcentration=True, maxIter = 50, learningDecay = 0.51, \n",
    "          learningOffset=64., subsamplingRate = 0.05 )\n",
    "\n",
    "# fit model\n",
    "lda_model = lda.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity on training and testing data: 6.250731587840231,6.279818275269136\n"
     ]
    }
   ],
   "source": [
    "# getting log perplexity for test and train set\n",
    "lp_test, lp_train = lda_model.logPerplexity(df_test), lda_model.logPerplexity(df_train)\n",
    "print(\"Perplexity on training and testing data: \" + str(lp_train) + ',' + str(lp_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|topic|         termIndices|         termWeights|\n",
      "+-----+--------------------+--------------------+\n",
      "|    0|[0, 2, 3, 1, 4, 2...|[0.09498567947246...|\n",
      "|    1|[111, 20, 313, 16...|[0.03602289211376...|\n",
      "|    2|[63, 37, 52, 8, 9...|[0.03959405449781...|\n",
      "|    3|[7, 0, 6, 131, 12...|[0.08226881852123...|\n",
      "|    4|[71, 66, 151, 21,...|[0.03671807744532...|\n",
      "|    5|[1, 60, 41, 81, 3...|[0.09705852223369...|\n",
      "+-----+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print topics and top-weighted terms\n",
    "topics = lda_model.describeTopics(maxTermsPerTopic=10)\n",
    "vocabulary = model.stages[2].vocabulary\n",
    "\n",
    "topics.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------+\n",
      "|words                                                                          |\n",
      "+-------------------------------------------------------------------------------+\n",
      "|[food, great, service, place, time, table, back, came, wait, server]           |\n",
      "|[coffee, pretty, lobster, definitely, food, chocolate, free, stars, cake, cafe]|\n",
      "|[pizza, salad, cheese, ordered, menu, steak, got, sauce, pasta, nice]          |\n",
      "|[chicken, food, restaurant, thai, order, place, rice, curry, ordered, wings]   |\n",
      "|[burger, pork, ramen, sauce, meat, beef, soup, fries, fried, noodles]          |\n",
      "|[place, sushi, lunch, fish, always, love, nice, tea, roll, pho]                |\n",
      "+-------------------------------------------------------------------------------+\n",
      "\n",
      "+--------------------------------------------------------------------------------+\n",
      "|weights                                                                         |\n",
      "+--------------------------------------------------------------------------------+\n",
      "|[0.0950, 0.0528, 0.0330, 0.0306, 0.0240, 0.0180, 0.0158, 0.0143, 0.0117, 0.0108]|\n",
      "|[0.0360, 0.0215, 0.0214, 0.0178, 0.0144, 0.0144, 0.0129, 0.0129, 0.0113, 0.0104]|\n",
      "|[0.0396, 0.0261, 0.0247, 0.0179, 0.0149, 0.0146, 0.0135, 0.0119, 0.0117, 0.0115]|\n",
      "|[0.0823, 0.0540, 0.0431, 0.0276, 0.0264, 0.0182, 0.0159, 0.0154, 0.0138, 0.0131]|\n",
      "|[0.0367, 0.0282, 0.0238, 0.0227, 0.0219, 0.0200, 0.0193, 0.0186, 0.0177, 0.0159]|\n",
      "|[0.0971, 0.0429, 0.0252, 0.0243, 0.0221, 0.0211, 0.0200, 0.0181, 0.0135, 0.0132]|\n",
      "+--------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ListOfIndexToWords = functions.udf(lambda wl: list([vocabulary[w] for w in wl]))\n",
    "FormatNumbers = functions.udf(lambda nl: [\"{:1.4f}\".format(x) for x in nl])\n",
    "\n",
    "topics.select(ListOfIndexToWords(topics.termIndices).alias('words')).show(truncate=False, n=number_of_topics)\n",
    "topics.select(FormatNumbers(topics.termWeights).alias('weights')).show(truncate=False, n=number_of_topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"PythonLDA/\"\n",
    "\n",
    "model.save(path + 'Count')\n",
    "ldaModel.save(path + 'LDAModel_stem'+ model_number)\n",
    "lda.save(path + 'LDA_'+ model_number)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
